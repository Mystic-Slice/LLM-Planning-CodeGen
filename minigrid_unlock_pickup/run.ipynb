{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5107e89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32f139a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from minigrid.wrappers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f2d4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SEEDS = list(range(1000))\n",
    "GRID_SEEDS = list(range(100))\n",
    "# GRID_SEEDS = [42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64d7bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MiniGrid-UnlockPickup-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b513688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unwrapped(env):\n",
    "    while hasattr(env, 'env'):\n",
    "        env = env.env\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80239948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_obs(obs):\n",
    "    rgb_obs_env = RGBImgObsWrapper(env)\n",
    "\n",
    "    obs = rgb_obs_env.observation(obs)\n",
    "\n",
    "    plt.imshow(obs['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1f2259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_obs(env):\n",
    "    obs = get_unwrapped(env).gen_obs()\n",
    "    fully_obs = FullyObsWrapper(env).observation(obs)\n",
    "    return fully_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a67fa4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(env):\n",
    "    # convert to np array\n",
    "    grid = env.get_wrapper_attr('pprint_grid')()\n",
    "    split_rows = grid.split('\\n')\n",
    "    grid_cells = [[line[i:i+2] for i in range(0, len(line), 2)] for line in split_rows]\n",
    "\n",
    "    OBJ_IDX_TO_TYPE = {\n",
    "        'W': \"WALL\",\n",
    "        'D': \"DOOR\",\n",
    "        'K': \"KEY\",\n",
    "        'A': \"BALL\",\n",
    "        'B': \"BOX\",\n",
    "        'L': \"DOOR\",\n",
    "        'V': 'AGENT',\n",
    "        '^': 'AGENT',\n",
    "        '>': 'AGENT',\n",
    "        '<': 'AGENT',\n",
    "        ' ': \"\",\n",
    "    }\n",
    "    input_grid = [[OBJ_IDX_TO_TYPE[c[0]] for c in row] for row in grid_cells]\n",
    "\n",
    "    direction = None\n",
    "    if 'V' in grid:\n",
    "        direction = 'DOWN'\n",
    "    elif '^' in grid:\n",
    "        direction = 'UP'\n",
    "    elif '<' in grid:\n",
    "        direction = 'LEFT'\n",
    "    elif '>' in grid:\n",
    "        direction = 'RIGHT'\n",
    "\n",
    "    return input_grid, direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "217f6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_input_grid(grid):\n",
    "    OBJ_IDX_TO_TYPE = {\n",
    "        'W': \"WALL\",\n",
    "        'D': \"DOOR\",\n",
    "        'K': \"KEY\",\n",
    "        'A': \"BALL\",\n",
    "        'B': \"BOX\",\n",
    "        'L': \"DOOR\",\n",
    "        'V': 'AGENT',\n",
    "        '^': 'AGENT',\n",
    "        '>': 'AGENT',\n",
    "        '<': 'AGENT',\n",
    "    }\n",
    "    for row in grid:\n",
    "        print('[', end='')\n",
    "        print(\",\".join([f'\"{c}\"' for c in row]), end='],\\n')\n",
    "        # print('],')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed6eacfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_MAP = {\n",
    "    'LEFT': 0,\n",
    "    'RIGHT': 1,\n",
    "    'MOVE': 2,\n",
    "    'PICKUP': 3,\n",
    "    'DROP': 4,\n",
    "    'UNLOCK': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9025937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(env, actions):\n",
    "    action_ids = [ACTIONS_MAP[action] for action in actions]\n",
    "\n",
    "    reward = 0\n",
    "    done = False\n",
    "\n",
    "    for action in action_ids:\n",
    "        obs, reward, done, _, _ = env.step(action)\n",
    "\n",
    "    return reward, done\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d797b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_codes.o3_mini import solve as solve_o3_mini\n",
    "from model_codes.claude import solve as solve_claude\n",
    "from model_codes.o1 import solve as solve_o1\n",
    "from model_codes.deepseek import solve as solve_deepseek\n",
    "from model_codes.gemini_25_pro import solve as solve_gemini_25_pro\n",
    "from model_codes.gpt_4o import solve as solve_gpt_4o\n",
    "\n",
    "from model_codes_iter.o3_mini_b import solve as solve_o3_mini_b\n",
    "from model_codes_iter.o3_mini_c import solve as solve_o3_mini_c\n",
    "\n",
    "\n",
    "from model_codes_iter.o1_b import solve as solve_o1_b\n",
    "from model_codes_iter.o1_c import solve as solve_o1_c\n",
    "\n",
    "\n",
    "from model_codes_iter.claude_b import solve as solve_claude_b\n",
    "from model_codes_iter.claude_c import solve as solve_claude_c\n",
    "from model_codes_iter.claude_d import solve as solve_claude_d\n",
    "from model_codes_iter.claude_e import solve as solve_claude_e\n",
    "\n",
    "from model_codes_iter.deepseek_b import solve as solve_deepseek_b\n",
    "\n",
    "from model_codes_iter.gemini_25_pro_b import solve as solve_gemini_25_pro_b\n",
    "\n",
    "from model_codes_iter.gpt_4o_b import solve as solve_gpt_4o_b\n",
    "\n",
    "from model_codes.random_walk import solve as solve_random_walk\n",
    "from model_codes.greedy import solve as solve_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00467579",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHODS = {\n",
    "    'baseline': {\n",
    "        'random_walk': solve_random_walk,\n",
    "        'greedy': solve_greedy,\n",
    "    },\n",
    "    'direct_code_gen': {\n",
    "        # 'o3_mini': solve_o3_mini,\n",
    "        # 'claude': solve_claude,\n",
    "        # 'o1': solve_o1,\n",
    "        # 'deepseek': solve_deepseek,\n",
    "        # 'gemini_25_pro': solve_gemini_25_pro,\n",
    "        # 'gpt_4o': solve_gpt_4o,\n",
    "    },\n",
    "    'iterative': {\n",
    "        # 'o3_mini_b': solve_o3_mini_b,\n",
    "        # 'o3_mini_c': solve_o3_mini_c,\n",
    "        # 'o1_b': solve_o1_b,\n",
    "        # 'o1_c': solve_o1_c,\n",
    "        # 'claude_b': solve_claude_b,\n",
    "        # 'claude_c': solve_claude_c,\n",
    "        # 'claude_d': solve_claude_d,\n",
    "        # 'claude_e': solve_claude_e,\n",
    "        # 'deepseek_b': solve_deepseek_b,\n",
    "        # 'gemini_25_pro_b': solve_gemini_25_pro_b,\n",
    "        # 'gpt_4o_b': solve_gpt_4o_b,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9308e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_scores(scores, method_cls, method_name, grid_seed, reward, done):\n",
    "    if method_cls not in scores:\n",
    "        scores[method_cls] = {}\n",
    "    if method_name not in scores[method_cls]:\n",
    "        scores[method_cls][method_name] = {}\n",
    "    if grid_seed not in scores[method_cls][method_name]:\n",
    "        scores[method_cls][method_name][grid_seed] = {'reward': 0, 'done': 0}\n",
    "    \n",
    "    scores[method_cls][method_name][grid_seed]['reward'] = reward\n",
    "    scores[method_cls][method_name][grid_seed]['done'] = 1 if done else 0\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "848f2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(scores, return_df = False):\n",
    "    metrics = {}\n",
    "    data_points = []\n",
    "    for method_cls, method_scores in scores.items():\n",
    "        metrics[method_cls] = {}\n",
    "        for method_name, grid_scores in method_scores.items():\n",
    "            total_reward = sum([grid_score['reward'] for grid_score in grid_scores.values()])\n",
    "            total_done = sum([grid_score['done'] for grid_score in grid_scores.values()])\n",
    "            num_grids = len(grid_scores)\n",
    "            metrics[method_cls][method_name] = {\n",
    "                'total_reward': total_reward,\n",
    "                'total_done': total_done,\n",
    "                'num_grids': num_grids,\n",
    "                'avg_reward': total_reward / num_grids if num_grids > 0 else 0,\n",
    "                'avg_done': total_done / num_grids if num_grids > 0 else 0,\n",
    "            }\n",
    "\n",
    "            for grid_seed, grid_score in grid_scores.items():\n",
    "                data_points.append({\n",
    "                    'method_cls': method_cls,\n",
    "                    'method_name': method_name,\n",
    "                    'grid_seed': grid_seed,\n",
    "                    'reward': grid_score['reward'],\n",
    "                    'done': grid_score['done'],\n",
    "                })\n",
    "\n",
    "            # data_points.append({\n",
    "            #     'method_cls': method_cls,\n",
    "            #     'method_name': method_name,\n",
    "            #     'total_reward': total_reward,\n",
    "            #     'total_done': total_done,\n",
    "            #     'num_grids': num_grids,\n",
    "            #     'avg_reward': total_reward / num_grids if num_grids > 0 else 0,\n",
    "            #     'avg_done': total_done / num_grids if num_grids > 0 else 0,\n",
    "            # })\n",
    "\n",
    "    if return_df:\n",
    "        df = pd.DataFrame(data_points)\n",
    "        return metrics, df\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b26ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worst_grids(scores, method_cls, method_name, k=3):\n",
    "    grid_scores = scores[method_cls][method_name]\n",
    "    not_done_grids = [(k, v) for k, v in grid_scores.items() if v['done'] == 0]\n",
    "    \n",
    "    worst_grids = not_done_grids\n",
    "\n",
    "    done_grids = {k: v for k, v in grid_scores.items() if v['done'] == 1}\n",
    "    done_grids = sorted(done_grids.items(), key=lambda x: x[1]['reward'], reverse=True)\n",
    "    worst_grids += done_grids\n",
    "    return worst_grids[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3df638d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: random_walk\n",
      "Method: greedy\n",
      "Grid Seed: 99\r"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "\n",
    "for method_cls, methods_dict in METHODS.items():\n",
    "    for method_name, method in methods_dict.items():\n",
    "        print(f\"Method: {method_name}\")\n",
    "        for grid_seed in GRID_SEEDS:\n",
    "            print(f\"Grid Seed: {grid_seed}\\r\", end='')\n",
    "\n",
    "            env.reset(seed=grid_seed)\n",
    "            input_grid, direction = get_inputs(env)\n",
    "\n",
    "            actions = method(input_grid, direction)\n",
    "            # print(f\"Actions: {actions}\")\n",
    "\n",
    "            reward, done = eval(env, actions)\n",
    "            # print(f\"Done: {done}\")\n",
    "            # print(f\"Reward: {reward}\")\n",
    "            \n",
    "            scores = add_to_scores(scores, method_cls, method_name, grid_seed, reward, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19e22c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method Class: baseline\n",
      "  Method Name: random_walk\n",
      "    Average Reward: 0.0\n",
      "    Average Done: 0.0\n",
      "  Method Name: greedy\n",
      "    Average Reward: 0.7471562500000001\n",
      "    Average Done: 0.8\n"
     ]
    }
   ],
   "source": [
    "metrics = get_metrics(scores)\n",
    "for method_cls, method_scores in metrics.items():\n",
    "    print(f\"Method Class: {method_cls}\")\n",
    "    for method_name, s in method_scores.items():\n",
    "        print(f\"  Method Name: {method_name}\")\n",
    "        print(f\"    Average Reward: {s['avg_reward']}\")\n",
    "        print(f\"    Average Done: {s['avg_done']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8489e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, metrics_df = get_metrics(scores, return_df=True)\n",
    "metrics_df.to_csv('metrics_unlock_pickup.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7e22f23",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'iterative'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bad_grid_seed, results \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget_worst_grids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt_4o_b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      2\u001b[0m     env\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39mbad_grid_seed)\n\u001b[0;32m      3\u001b[0m     input_grid, direction \u001b[38;5;241m=\u001b[39m get_inputs(env)\n",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m, in \u001b[0;36mget_worst_grids\u001b[1;34m(scores, method_cls, method_name, k)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_worst_grids\u001b[39m(scores, method_cls, method_name, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     grid_scores \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmethod_cls\u001b[49m\u001b[43m]\u001b[49m[method_name]\n\u001b[0;32m      3\u001b[0m     not_done_grids \u001b[38;5;241m=\u001b[39m [(k, v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m grid_scores\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     worst_grids \u001b[38;5;241m=\u001b[39m not_done_grids\n",
      "\u001b[1;31mKeyError\u001b[0m: 'iterative'"
     ]
    }
   ],
   "source": [
    "for bad_grid_seed, results in get_worst_grids(scores, 'iterative', 'gpt_4o_b'):\n",
    "    env.reset(seed=bad_grid_seed)\n",
    "    input_grid, direction = get_inputs(env)\n",
    "\n",
    "    # print(f\"Grid Seed: {bad_grid_seed}\")\n",
    "    # print(results)\n",
    "    \n",
    "    print(\"<grid>\")\n",
    "    print_input_grid(input_grid)\n",
    "    print(\"</grid>\")\n",
    "    print(f\"<start_direction>\\n{direction}\\n</start_direction>\")\n",
    "    print(\"--------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions_lists = {\n",
    "#     \"direct\": [\"LEFT\", \"MOVE\", \"PICKUP\", \"LEFT\", \"MOVE\", \"MOVE\", \"RIGHT\", \"MOVE\", \"UNLOCK\", \"LEFT\", \"LEFT\", \"DROP\", \"RIGHT\", \"RIGHT\", \"MOVE\", \"MOVE\", \"MOVE\", \"MOVE\", \"RIGHT\", \"MOVE\", \"MOVE\", \"MOVE\", \"MOVE\", \"PICKUP\"],\n",
    "#     \"cot\": [\"LEFT\", \"MOVE\", \"PICKUP\", \"LEFT\", \"MOVE\", \"MOVE\", \"RIGHT\", \"MOVE\", \"UNLOCK\", \"MOVE\", \"MOVE\", \"MOVE\", \"MOVE\", \"MOVE\", \"RIGHT\", \"MOVE\", \"MOVE\", \"PICKUP\"],\n",
    "#     \"2_step\": [\"LEFT\", \"MOVE\", \"PICKUP\", \"LEFT\", \"MOVE\", \"MOVE\", \"RIGHT\", \"MOVE\", \"UNLOCK\", \"RIGHT\", \"DROP\", \"LEFT\", \"MOVE\", \"MOVE\", \"MOVE\", \"MOVE\", \"MOVE\", \"RIGHT\", \"MOVE\", \"MOVE\", \"RIGHT\", \"MOVE\", \"LEFT\", \"MOVE\", \"LEFT\", \"PICKUP\"],\n",
    "# }\n",
    "\n",
    "# for method, actions in actions_lists.items():\n",
    "#     print(f\"Method: {method}\")\n",
    "#     print(f\"Actions: {actions}\")\n",
    "\n",
    "#     env.reset(seed=42)\n",
    "#     input_grid, direction = get_inputs(env)\n",
    "#     reward, done = eval(env, actions)\n",
    "#     print(f\"Done: {done}\")\n",
    "#     print(f\"Reward: {reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
